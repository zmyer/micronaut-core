To add support for Kafka to an existing project, you should first add the Micronaut Kafka configuration to your build configuration. For example in Gradle:

.build.gradle
[source,groovy]
----
compile "io.micronaut.configuration:micronaut-kafka"
----

Or with Maven:

.Maven
[source,xml]
----
<dependency>
  <groupId>io.micronaut.configuration</groupId>
  <artifactId>micronaut-kafka</artifactId>
</dependency>
----

=== Configuring Kafka

The minimum requirement to configure Kafka is set the value of the `kafka.bootstrap.servers` property in `application.yml`:

.Configuring Kafka
[source,yaml]
----
kafka:
    bootstrap:
        servers: localhost:9092
----

The value can also be list of available servers:

.Configuring Kafka
[source,yaml]
----
kafka:
    bootstrap:
        servers:
            - foo:9092
            - bar:9092
----

TIP: You can also set the environment variable `KAFKA_BOOTSTRAP_SERVERS` to a comma separated list of values to externalize configuration.

=== Creating a Kafka Producer with @KafkaClient

To create a Kafka `Producer` that sends messages you can simply define an interface that is annotated with ann:configuration.kafka.annotation.KafkaClient[].

For example the following is a trivial `@KafkaClient` interface:

.ProductClient.java
[source,java]
----
include::{testskafka}/quickstart/ProductClient.java[tags=imports, indent=0]

include::{testskafka}/quickstart/ProductClient.java[tags=clazz, indent=0]
----

<1> The ann:configuration.kafka.annotation.KafkaClient[] annotation is used to designate this interface as a client
<2> The ann:configuration.kafka.annotation.Topic[] annotation indicates which topics the `ProducerRecord` should be published to
<3> The method defines two parameters: The parameter that is the Kafka key and the value.

NOTE: You can omit the key, however this will result in a `null` key which means Kafka will not know how to partition the record.

At compile time Micronaut will produce an implementation of the above interface. You can retrieve an instance of `ProductClient` either by looking up the bean from the api:context.ApplicationContext[] or by injecting the bean with `@Inject`:

.Using ProductClient
[source,java]
----
include::{testskafka}/DocTests.java[tags=quickstart, indent=0]
----


Note that since the `sendProduct` method returns `void` this means the method will send the `ProducerRecord` and block until the response is received. You can return a `Future` or rs:Publisher[] to support non-blocking message delivery.


=== Creating a Kafka Consumer with @KafkaListener

To listen to Kafka messages you can use the ann:configuration.kafka.annotation.KafkaListener[] annotation to define a message listener.

The following example will listen for messages published by the `ProductClient` in the previous section:

.ProductListener.java
[source,java]
----
include::{testskafka}/quickstart/ProductListener.java[tags=imports, indent=0]

include::{testskafka}/quickstart/ProductListener.java[tags=clazz, indent=0]
----

<1> The ann:configuration.kafka.annotation.KafkaListener[] is used with `offsetReset` set to `EARLIEST` which makes the listener start listening to messages from the beginning of the partition.
<2> The ann:configuration.kafka.annotation.Topic[] annotation is again used to indicate which topic(s) to subscribe to.
<3> The `receive` method defines 2 arguments: The argument that will receive the key and the argument that will receive the value.

